# On-Device-AI

## Overview
This project explores deploying AI models on mobile devices using quantization techniques to reduce model size and computation requirements while maintaining accuracy. We will go through loading a dataset, setting up a calibration/inference pipeline, preparing a floating-point model, performing post-training quantization, and deploying the quantized model on a device.

